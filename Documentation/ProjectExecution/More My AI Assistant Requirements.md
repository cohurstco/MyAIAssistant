# More My AI Assistant Requirements

The app is designed with a serverless architecture, employing serverless functions for each domain of knowledge. These functions, each supported by a Redis and a DynamoDB table, store information based on working memory and priority. This prioritization is determined by factors such as urgency, importance, complexity, effort, project focus, user's area of interest, resource requirements, and archiving needs. This unique combination of the Eisenhower Matrix and the PARA method enables the personal AGI to effectively prioritize its focus, collect the necessary data from the user, learn more about the user through interactions, and retrain the context of previous conversations to better assist the user in achieving their goals.
Create backend ETL serverless functions to move data from short-term to long-term storage methods and/or delete data based on the frequency of calls and usage to cut costs. Keep DB sizes small and cheap.
The services will be based on higher concepts and then divided into more detailed subtypes, categories, and topic domains.
The app leverages Lambda functions with trained LLMs to generate answers. These answers are derived from the context or information collected from users, resources, or external sources. Alternatively, the app can generate the code required to construct, test, and deploy to retrieve the necessary information.
GraphQL is utilized to store relationships between data, structure, metadata, and context. This allows for efficient data retrieval and manipulation within the system.
Could use scheduled or triggered functions to scrub the internet based on project topics, tags, and lists. and lists
Summarize by headers and content list pages, highlighting topic sentences, key points, and concepts without losing context.
A single interface for input and output with multimedia of choice for the multimedia function changes it into whatever is needed for the following input or output.
Use Redis, DynamoDB, or S3 for in-app calls for needed data, or ask another API endpoint question to a domain knowledge function with an LLM to process the request and return the output.
To communicate with other external sources, two-step authentication, passkeys, authorization, JWTs, certifications, clearance, and encryption are needed.
Use metadata fields like related tags, date/timestamps, person, place, thing, interaction, relationship, topic, context, and body functions like heart rate, breathing, or location. Logs, events, table inserts, and updates by user ID and timestamps.
Use different databases for different data types: time series, documents, noSQL, vector.
You can input your data from voice, video, social media links, APIs, RSS feeds, podcasts, YouTube, search results, and data scraping by taking pages to their bare pieces of HTML, images, links, and tags information. These could be plugins and integration of other systems based on the project and area of focus. Each would need its API and functions in the system.
Use a data lake and AWS EventBridge, step functions, and event messaging to bring data into the system. Asynchronously collect any needed relative, correlated information into the database layer for organizing, prioritizing, standardizing, and refining. This should give the user an.
Look for biases, opinions, and keywords in data and sentences or if they are not related to the research, area of focus, or projects/goals of the user.
Look for relationships and correlations among the topics, questions, or inputs asked and see if you can make connections or trends between the themes, language usage, or related concepts between categories.
Use S3 systems for longer-term information, archiving, and eventually soft deleting unused data. It would be better to delete it and cause a loss of memory.
It is easier to scale in and out than up and down. This is because you can build new instances, test them, deploy blue/green to transfer users to them and kill old instances (of thought) while changing configurations. Restarting requires transferring users to the newly changed instance and restarting the machine to come up before switching people back to it, which is more overhead.
